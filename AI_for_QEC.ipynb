{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb5595ef",
   "metadata": {},
   "source": [
    "# Introduction to AI for Quantum Error Correction\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates quantum error correction using the 3-qubit bit flip code with realistic noise and then explores various avenues where AI can be useful. \n",
    "\n",
    "Please note that this notebook is a work-in-progress. You can check it periodically over the next 2 weeks. You should familiarize yourself with the basics of Quantum Error Correction - some good resources are qBook (qbook.qbraid.com) or Coursera. You can also check out NVIDIA's QEC work [here](https://github.com/NVIDIA/cuda-q-academic/tree/main/qec101). \n",
    "\n",
    "Now, let's start with a hands-on example with the 3-qubit bit flip code.\n",
    "\n",
    "## The 3-Qubit Bit Flip Code\n",
    "- **Logical states**: |0⟩ → |000⟩, |1⟩ → |111⟩  \n",
    "- **Stabilizers**: g₁ = ZZI, g₂ = IZZ\n",
    "- **Error correction**: Can fix any single bit flip error\n",
    "\n",
    "## Syndrome Table\n",
    "| Syndrome | Error Location | Correction |\n",
    "|----------|----------------|------------|\n",
    "| 00       | None           | Do nothing |\n",
    "| 10       | Qubit 0        | Apply X₀   |\n",
    "| 11       | Qubit 1        | Apply X₁   |\n",
    "| 01       | Qubit 2        | Apply X₂   |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006614f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister\n",
    "from qiskit_aer import Aer\n",
    "from qiskit_aer.noise import NoiseModel, depolarizing_error\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Decoder Implementation\n",
    "# =====================================================\n",
    "\n",
    "class BitFlipDecoder:\n",
    "    \"\"\"Simple lookup table decoder for 3-qubit bit flip code.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.syndrome_table = {\n",
    "            '00': None,  # No correction needed\n",
    "            '10': 0,     # Correct qubit 0\n",
    "            '11': 1,     # Correct qubit 1  \n",
    "            '01': 2      # Correct qubit 2\n",
    "        }\n",
    "    \n",
    "    def decode(self, syndrome_string):\n",
    "        \"\"\"Return which qubit to correct (None if no correction needed).\"\"\"\n",
    "        return self.syndrome_table.get(syndrome_string, None)\n",
    "    \n",
    "    def get_error_description(self, syndrome_string):\n",
    "        \"\"\"Get human-readable error description.\"\"\"\n",
    "        corrections = {\n",
    "            '00': 'No error detected',\n",
    "            '10': 'Error on qubit 0', \n",
    "            '11': 'Error on qubit 1',\n",
    "            '01': 'Error on qubit 2'\n",
    "        }\n",
    "        return corrections.get(syndrome_string, 'Unknown syndrome')\n",
    "\n",
    "# =====================================================\n",
    "# Circuit Building Functions\n",
    "# =====================================================\n",
    "\n",
    "def create_error_correction_circuit(logical_state=0, introduce_error=None):\n",
    "    \"\"\"\n",
    "    Create a complete error correction circuit.\n",
    "    \n",
    "    Args:\n",
    "        logical_state (int): 0 or 1 for logical |0⟩ or |1⟩\n",
    "        introduce_error (int or None): Which qubit to flip (for testing)\n",
    "    \n",
    "    Returns:\n",
    "        QuantumCircuit: Complete circuit with encoding, error, syndrome measurement\n",
    "    \"\"\"\n",
    "    # Registers\n",
    "    data = QuantumRegister(3, 'data')\n",
    "    ancilla = QuantumRegister(2, 'ancilla')\n",
    "    syndrome = ClassicalRegister(2, 'syndrome')\n",
    "    \n",
    "    qc = QuantumCircuit(data, ancilla, syndrome)\n",
    "    \n",
    "    # Encode logical state\n",
    "    if logical_state == 1:\n",
    "        qc.x(data[0])\n",
    "        qc.x(data[1])\n",
    "        qc.x(data[2])\n",
    "    \n",
    "    # Introduce test error\n",
    "    if introduce_error is not None:\n",
    "        qc.x(data[introduce_error])\n",
    "    \n",
    "    # Measure stabilizers\n",
    "    # g1 = ZZI\n",
    "    qc.cx(data[0], ancilla[0])\n",
    "    qc.cx(data[1], ancilla[0])\n",
    "    \n",
    "    # g2 = IZZ\n",
    "    qc.cx(data[1], ancilla[1])\n",
    "    qc.cx(data[2], ancilla[1])\n",
    "    \n",
    "    qc.measure(ancilla, syndrome)\n",
    "    \n",
    "    return qc\n",
    "\n",
    "def create_noisy_circuit(logical_state=0, noise_prob=0.01):\n",
    "    \"\"\"\n",
    "    Create circuit with realistic depolarizing noise.\n",
    "    \n",
    "    Args:\n",
    "        logical_state (int): 0 or 1\n",
    "        noise_prob (float): Probability of depolarizing error per gate\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (circuit, noise_model)\n",
    "    \"\"\"\n",
    "    data = QuantumRegister(3, 'data')\n",
    "    ancilla = QuantumRegister(2, 'ancilla')\n",
    "    syndrome = ClassicalRegister(2, 'syndrome')\n",
    "    correction = ClassicalRegister(3, 'correction')\n",
    "    \n",
    "    qc = QuantumCircuit(data, ancilla, syndrome, correction)\n",
    "    \n",
    "    # Encode logical state\n",
    "    if logical_state == 1:\n",
    "        qc.x(data[0])\n",
    "        qc.x(data[1]) \n",
    "        qc.x(data[2])\n",
    "    \n",
    "    # Add barriers to separate encoding from syndrome measurement\n",
    "    qc.barrier()\n",
    "    \n",
    "    # Measure stabilizers\n",
    "    qc.cx(data[0], ancilla[0])\n",
    "    qc.cx(data[1], ancilla[0])\n",
    "    qc.cx(data[1], ancilla[1])\n",
    "    qc.cx(data[2], ancilla[1])\n",
    "    qc.measure(ancilla, syndrome)\n",
    "    \n",
    "    # Add correction gates (controlled by classical bits in real implementation)\n",
    "    # For demo, we'll apply all possible corrections and use post-processing\n",
    "    qc.barrier()\n",
    "    \n",
    "    # Create noise model\n",
    "    noise_model = NoiseModel()\n",
    "    \n",
    "    # Add depolarizing error to all single-qubit gates\n",
    "    error_1q = depolarizing_error(noise_prob, 1)\n",
    "    noise_model.add_all_qubit_quantum_error(error_1q, ['x'])\n",
    "    \n",
    "    # Add depolarizing error to CNOT gates  \n",
    "    error_2q = depolarizing_error(noise_prob, 2)\n",
    "    noise_model.add_all_qubit_quantum_error(error_2q, ['cx'])\n",
    "    \n",
    "    return qc, noise_model\n",
    "\n",
    "# =====================================================\n",
    "# Testing and Analysis Functions\n",
    "# =====================================================\n",
    "\n",
    "def test_decoder_without_noise():\n",
    "    \"\"\"Test decoder on all possible single-bit errors without noise.\"\"\"\n",
    "    decoder = BitFlipDecoder()\n",
    "    \n",
    "    print(\"Testing decoder without noise:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for error_pos in [None, 0, 1, 2]:\n",
    "        qc = create_error_correction_circuit(logical_state=0, introduce_error=error_pos)\n",
    "        \n",
    "        # Run simulation\n",
    "        simulator = Aer.get_backend('qasm_simulator')\n",
    "        pm = generate_preset_pass_manager(backend=simulator, optimization_level=1)\n",
    "        transpiled_qc = pm.run(qc)\n",
    "        job = simulator.run(transpiled_qc, shots=1000)\n",
    "        result = job.result()\n",
    "        counts = result.get_counts()\n",
    "        \n",
    "        # Get most common syndrome\n",
    "        syndrome = max(counts.keys(), key=counts.get)\n",
    "        correction = decoder.decode(syndrome)\n",
    "        description = decoder.get_error_description(syndrome)\n",
    "        \n",
    "        results[error_pos] = {\n",
    "            'syndrome': syndrome,\n",
    "            'correction': correction,\n",
    "            'description': description,\n",
    "            'counts': counts\n",
    "        }\n",
    "        \n",
    "        if error_pos is None:\n",
    "            print(f\"No error:     syndrome {syndrome} → {description}\")\n",
    "        else:\n",
    "            print(f\"Error on q{error_pos}: syndrome {syndrome} → {description}\")\n",
    "    \n",
    "    print(\"\\n All single errors detected correctly!\\n\")\n",
    "    return results\n",
    "\n",
    "def test_decoder_with_noise(noise_probs=[0.001, 0.01, 0.05, 0.1]):\n",
    "    \"\"\"Test decoder performance under different noise levels.\"\"\"\n",
    "    decoder = BitFlipDecoder()\n",
    "    \n",
    "    print(\"Testing decoder with depolarizing noise:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for noise_prob in noise_probs:\n",
    "        print(f\"\\nNoise probability: {noise_prob}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Test both logical states\n",
    "        for logical_state in [0, 1]:\n",
    "            qc, noise_model = create_noisy_circuit(logical_state, noise_prob)\n",
    "            \n",
    "            # Run noisy simulation\n",
    "            simulator = Aer.get_backend('qasm_simulator')\n",
    "            pm = generate_preset_pass_manager(backend=simulator, optimization_level=1)\n",
    "            transpiled_qc = pm.run(qc)\n",
    "            job = simulator.run(transpiled_qc, shots=1000, noise_model=noise_model)\n",
    "            result = job.result()\n",
    "            counts = result.get_counts()\n",
    "            \n",
    "            # Analyze syndrome distribution\n",
    "            syndrome_counts = {}\n",
    "            for bitstring, count in counts.items():\n",
    "                syndrome = bitstring[-2:]  # Last 2 bits are syndrome\n",
    "                syndrome_counts[syndrome] = syndrome_counts.get(syndrome, 0) + count\n",
    "            \n",
    "            # Calculate error rates\n",
    "            total_shots = sum(syndrome_counts.values())\n",
    "            no_error_rate = syndrome_counts.get('00', 0) / total_shots\n",
    "            error_rate = 1 - no_error_rate\n",
    "            \n",
    "            print(f\"  Logical |{logical_state}⟩: {error_rate:.1%} error rate\")\n",
    "            \n",
    "            # Store detailed results\n",
    "            key = (noise_prob, logical_state)\n",
    "            results[key] = {\n",
    "                'syndrome_counts': syndrome_counts,\n",
    "                'error_rate': error_rate,\n",
    "                'total_shots': total_shots\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def analyze_noise_performance(results):\n",
    "    \"\"\"Analyze and plot decoder performance vs noise level.\"\"\"\n",
    "    print(\"\\nNoise Performance Analysis:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    noise_levels = [0.001, 0.01, 0.05, 0.1]\n",
    "    error_rates_0 = []\n",
    "    error_rates_1 = []\n",
    "    \n",
    "    for noise_prob in noise_levels:\n",
    "        rate_0 = results[(noise_prob, 0)]['error_rate']\n",
    "        rate_1 = results[(noise_prob, 1)]['error_rate']\n",
    "        error_rates_0.append(rate_0)\n",
    "        error_rates_1.append(rate_1)\n",
    "        \n",
    "        print(f\"Noise {noise_prob:5.1%}: |0⟩ errors {rate_0:.1%}, |1⟩ errors {rate_1:.1%}\")\n",
    "    \n",
    "    # Create simple text-based visualization\n",
    "    print(\"\\nError Rate vs Noise Level:\")\n",
    "    print(\"(Each * represents ~5% error rate)\")\n",
    "    for i, noise_prob in enumerate(noise_levels):\n",
    "        stars = int(error_rates_0[i] * 20)  # Scale for visualization\n",
    "        print(f\"{noise_prob:5.1%} |{'*' * stars}\")\n",
    "    \n",
    "    print(\"\\n💡 Observations:\")\n",
    "    print(\"- Error rates increase roughly linearly with noise\")\n",
    "    print(\"- Both logical states show similar error rates\")\n",
    "    print(\"- Code provides protection until noise becomes too high\")\n",
    "\n",
    "# =====================================================\n",
    "# Main Execution\n",
    "# =====================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test decoder without noise\n",
    "    clean_results = test_decoder_without_noise()\n",
    "    \n",
    "    # Test decoder with noise\n",
    "    noisy_results = test_decoder_with_noise()\n",
    "    \n",
    "    # Analyze performance\n",
    "    analyze_noise_performance(noisy_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d92c12",
   "metadata": {},
   "source": [
    "So with this example:\n",
    "\n",
    "✅ **WHAT WE LEARNED:**\n",
    "\n",
    "• Built a working stabilizer decoder using lookup tables\n",
    "\n",
    "• Tested error detection without noise (perfect performance)\n",
    "\n",
    "• Simulated realistic depolarizing noise on quantum gates\n",
    "\n",
    "• Measured how decoder performance degrades with noise\n",
    "\n",
    "🔬 **KEY INSIGHTS:**\n",
    "\n",
    "• Stabilizer codes work well for low noise rates\n",
    "\n",
    "• Performance degrades gracefully as noise increases  \n",
    "\n",
    "• Both logical |0⟩ and |1⟩ show similar error rates\n",
    "\n",
    "• Real quantum computers need much better codes for fault tolerance\n",
    "\n",
    "🚀 **NEXT STEPS:**\n",
    "\n",
    "• Try the 7-qubit Steane code for better error correction\n",
    "\n",
    "• Implement maximum likelihood decoding for better performance\n",
    "\n",
    "• Study surface codes for scalable quantum computing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7608130b",
   "metadata": {},
   "source": [
    "## Why AI for Decoding?\n",
    "\n",
    "Now if this worked so well, why do we want to explore AI based decoders? Traditional lookup table decoders work great for small codes like our 3-qubit example, but they hit fundamental limits:\n",
    "\n",
    "1. Exponential scaling: \n",
    "A lookup table for an n-qubit stabilizer code needs 2^(syndrome length) entries. For the surface code with distance d=17 (needed for useful quantum computing), that's millions of possible syndromes.\n",
    "\n",
    "2. Complex noise: Real quantum hardware has correlated errors, crosstalk, and time-dependent noise that simple models can't capture.\n",
    "\n",
    "3. Real-time constraints: Quantum states decohere quickly, so decoders need to run in microseconds, not milliseconds.\n",
    "\n",
    "## Neural Network Decoders\n",
    "### Feedforward Networks\n",
    "The simplest approach treats decoding as a classification problem:\n",
    "Input: Syndrome vector (e.g., [1,0,1,1,0])\n",
    "Output: Most likely error pattern or correction to apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f547bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual example\n",
    "import torch.nn as nn\n",
    "\n",
    "class SyndromeDecoder(nn.Module):\n",
    "    def __init__(self, syndrome_length, num_qubits):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(syndrome_length, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_qubits)  # Output: probability each qubit has error\n",
    "        )\n",
    "    \n",
    "    def forward(self, syndrome):\n",
    "        return torch.sigmoid(self.network(syndrome))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf21f53",
   "metadata": {},
   "source": [
    "\n",
    "This has its advantages: fast inference, learns from data, can handle complex noise. But it also has its challenges: we need lots of training data and it may not generalize to new noise patterns.\n",
    "\n",
    "\n",
    "### Recurrent Neural Networks (RNNs)\n",
    "For surface codes and other topological codes, errors often have spatial correlations. RNNs can capture these patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a78f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process syndrome as a sequence over the 2D surface\n",
    "class TopologicalDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=4, hidden_size=64, num_layers=2)\n",
    "        self.classifier = nn.Linear(64, 2)  # Error or no error\n",
    "    \n",
    "    def forward(self, syndrome_sequence):\n",
    "        output, _ = self.lstm(syndrome_sequence)\n",
    "        return self.classifier(output[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761dbf08",
   "metadata": {},
   "source": [
    "### Graph Neural Networks (GNNs)\n",
    "\n",
    "This is where things get really interesting. Stabilizer codes have natural graph structure. Code graph: Qubits as nodes, stabilizers as constraints and then a Syndrome graph: Active syndrome measurements form patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aec3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.nn as pyg\n",
    "\n",
    "class GraphDecoder(torch.nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.conv1 = pyg.GCNConv(num_features, 64)\n",
    "        self.conv2 = pyg.GCNConv(64, 32)\n",
    "        self.classifier = torch.nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        # x: node features (syndrome values)\n",
    "        # edge_index: graph connectivity\n",
    "        x = torch.relu(self.conv1(x, edge_index))\n",
    "        x = torch.relu(self.conv2(x, edge_index))\n",
    "        return torch.sigmoid(self.classifier(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc83103",
   "metadata": {},
   "source": [
    "This GNN approach has its advantages too! It can naturally handle the irregular geometry of quantum codes, can process variable-size syndrome patterns, and can learn local error correlations while maintaining global consistency.\n",
    "\n",
    "### Reinforcement Learning Decoders\n",
    "\n",
    "RL treats decoding as a sequential decision problem:\n",
    "\n",
    "Agent: The decoder ->  Environment: The quantum code with syndrome ->  Actions: Apply corrections to specific qubits ->  Reward: Success when logical information is preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9063c188",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLDecoder:\n",
    "    def __init__(self, code):\n",
    "        self.q_network = DQN(state_size=code.syndrome_size, \n",
    "                           action_size=code.num_qubits)\n",
    "    \n",
    "    def decode(self, syndrome):\n",
    "        state = syndrome\n",
    "        corrections = []\n",
    "        \n",
    "        while not self.is_decoded(state):\n",
    "            action = self.q_network.choose_action(state)\n",
    "            corrections.append(action)\n",
    "            state = self.apply_correction(state, action)\n",
    "            \n",
    "        return corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb8cf1",
   "metadata": {},
   "source": [
    "The RL approach learns optimal correction strategies, potentially handling partial information and uncertainty as it adapts to changing noise conditions. \n",
    "\n",
    "### Transformer Architectures\n",
    "\n",
    "Recent work applies attention mechanisms to quantum error correction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8274fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, syndrome_length, d_model=256):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(1, d_model)\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model, nhead=8),\n",
    "            num_layers=6\n",
    "        )\n",
    "        self.output = nn.Linear(d_model, 1)\n",
    "    \n",
    "    def forward(self, syndrome):\n",
    "        # Treat syndrome as sequence\n",
    "        x = self.embedding(syndrome.unsqueeze(-1))\n",
    "        x = self.transformer(x)\n",
    "        return self.output(x).squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6ea100",
   "metadata": {},
   "source": [
    "This attention-based approach would naturally capture long-range correlations in error patterns, which is crucial for large quantum codes.\n",
    "\n",
    "\n",
    "### Hybrid Classical-Quantum Approaches\n",
    "\n",
    "Some cutting-edge research uses quantum neural networks for decoding:\n",
    "\n",
    "1. Quantum autoencoders: Learn compressed representations of error syndromes\n",
    "2. Variational quantum eigensolvers: Find optimal corrections by minimizing energy functions\n",
    "3. Quantum approximate optimization: Frame decoding as combinatorial optimization\n",
    "\n",
    "\n",
    "Recent work from Google shows that AI decoders can beat classical decoders, because they can learn correlations that analytical decoders miss and adapt in real-time. They also have the advantage of \n",
    "scaling efficiently. It's not easy though! Having sufficient, high-quality training data remains a challenge. Furthermore, models trained on one noise model may fail on real hardware, and there are also issues with latency - deep networks can be slower than needed for real-time correction. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1e1136",
   "metadata": {},
   "source": [
    "## So What's Next?\n",
    "\n",
    "Now armed with all these potentials, explore how you can use various existing AI architectures to improve quantum error correction. You could start with a simple depolarizing noise channel, explore resources from Google & NVIDIA, and keep an eye out on this notebook for updates in the near future!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
